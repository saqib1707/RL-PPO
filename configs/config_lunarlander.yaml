# training hparams
num_train_steps: 1000000
update_interval: 1000
num_epochs: 100
batch_size: 64
gamma: 0.99
eps_clip: 0.2
action_std_init: 0.5
action_std_decay_rate: 0.05
min_action_std: 0.1
entropy_coef: 0.01
value_loss_coef: 0.5
max_grad_norm: 0.5
mode: "train"

# network hparams
agent: "ppo"
hidden_dim: 64
activation: "tanh"
lr_actor: 3.0e-4
lr_critic: 1.0e-3

# env hparams
env_name: "LunarLander-v2"
continuous_action_space: false
max_eps_steps: 300
random_seed: 42

# logging hparams
wandb_project: "ppo-experiments"
wandb_entity: "saqib1707"
exp_name: ""
# run_id: 1
# log_interval: ${max_eps_steps * 5}
# save_interval: ${max_eps_steps * 10}
log_interval: 10000
save_interval: 100000
log_dir: "../logs/"
ckpt_dir: "../checkpoints/"

# evaluation hparams
num_eval_eps: 100
eval_ckpt_name: "CartPole-v1_step_500000.pt"
render_mode: null